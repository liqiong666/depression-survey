% !TEX root = tnnls_relation_gait.tex

\ifx\allfiles\undefined
    \input{tnnls_prefix}
\fi

\section{Depression recognition method based on Audiovisual data}
\label{sec_approach}

Depression is now the most common type of psychological disorder, manifested as a single or repeated multiple depressive episodes, slow clinical behavior, passive and lazy life, do not want to do anything, do not want to contact and interact with people around, often sitting alone, or lying in bed all day, living alone behind closed doors, alienating friends and relatives, avoiding social interaction, etc.. Second, the patient mainly shows significant and persistent depression, depression and pessimism. The patient's thinking is slow, unresponsive, and blocked. Clinically, there is a decrease in active speech, a significant slowdown in speech, a low voice, and difficulty in answering questions, and in severe cases, communication is not smooth. These characteristics are all abnormalities of depressed patients compared to healthy people and can be captured visually or audibly, which can be used to identify depression.

In recent years, there has been an increasing interest in identifying depression from behavioral signals and analyzing abnormal expressive behaviors that may result from depression, such as facial expressions that become sluggish, frequent avoidance of eye contact with others, and use of short sentences with a flat tone when speaking, and many researchers have found that depression identification can be well achieved by comparative analysis of these characteristics.

AVEC is an expression recognition challenge held every year since 2011, jointly organized by Imperial College London, University of Nottingham, Queen Mary University, USC and University of Passau, Germany, etc. It is recognized as the top international competition in the field of affective computing. AVEC 2013 started to introduce the task of depression recognition, considering the auditory-visual based analysis of depression as a regression problem or classification problems.

\subsection{Facial expression}
\label{sec_fquality}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[tbp]
	\centering	
	\label{fig_hard_case1}\includegraphics[width=0.8\linewidth]{figures/depression/facial-AVEC.png}		
	\caption{
	Samples from AVEC datasets.
	}
	\label{facial-AVEC}
\end{figure}

\begin{figure}[tbp]
	\centering	
	\label{fig_hard_case1}\includegraphics[width=0.8\linewidth]{figures/depression/facial.png}		
	\caption{
	Flow chart of expression-based depression recognition model.
	}
	\label{facial}
\end{figure}

A person's personality and mood can be seen from his face, and some studies have found that the appearance and temperament of patients with depression are also different from ordinary people.
Zhu et al.~\cite{0Identifying} research team of the institute of psychology of the Chinese Academy of Sciences studied 100 people with mental diseases. They asked 100 patients to read neutral articles through a special technology. From the research process, it was found that these patients frowned and drooped corners of their mouths when reading aloud, and a few tears appeared in their eyes, just like crying, looking very sad.

In order to study the relationship between patients' depression severity and facial expression over time, Girard et al.~\cite{2013Social} designed a study to track the subjects for two years, and collected the data of 36 patients with severe depression at the beginning and reduced symptoms after two years. Through the analysis of facial expressions in video data by manual and automatic systems, it showed that the automatic coding of Facial Action Coding System (FACS) action units is highly consistent with the manual coding, and showed a similar effect in the change of depression severity over time.

The results showed that when the severity of patients' symptoms was high, participants made more facial expressions related to contempt and smiled less, and those smiles were more likely to be accompanied by facial actions related to contempt. These results were consistent with the performance of Exchange-Oriented Withdrawal in the "Social Risk Hypothesis" of depression, indicating that patients with depression show more withdrawal in social intercourse. According to this hypothesis, when patients have severe symptoms, they will stay away from others to protect themselves from expected rejection, contempt and social exclusion~\cite{2005Emotion,BYLSMA2008676,2017Facial}.

\subsubsection{Facial expression depression recognition based on machine learning}
\label{sec_fquality}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

To achieve depression recognition from facial images, traditional solutions for vision-based automatic depression diagnosis systems usually include several steps as shown in Fig \ref{facial}: first, facial images are recognized and segmented from the raw video data, then features are extracted, and finally the features are fed into a classifier for classification or regression.


Machine learning can be divided into traditional machine based on the depth of the model structure learning and deep learning, which are now often applied to tasks such as vision and speech on tasks such as vision and speech. While traditional machine learning algorithms are suitable for small amounts of data, deep learning has higher performance on larger data sets.
%Machine learning is used in facial feature feature extraction and classification in facial features research.

Traditional machine learning methods such as SVM, naive Bayes (NB), RF and logistic regression (LR) are the most commonly used classifiers in the study of facial features of depressed patients~\cite{2017A,2018A,2020Automatic,2021Classifying}.


\subsubsection{Facial expression depression recognition based on deep learning}
\label{sec_fquality}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Convolutional neural networks (CNNs) are the most commonly used deep learning networks for facial recognition research in recent years. Many researches based on CNN and its innovative architectures such as three-dimensional CNN (C3D), modality separation networks (MSN), deep residual regression convolutional neural networks (DRR-CNN) for recognizing, classifying, and predicting human emotions, as well as exploring how facial action intensity changes from low to high levels of emotion~\cite{2019Combining,2019Multi,2020Encoding,2020A,2020Visually,2020Depression}. There are also studies that build on CNNs by embedding expectation loss into ResNet-50, a residual neural network, for distributional learning, which allows exploring the sequential relationship between facial images and depression levels to better predict depression levels~\cite{2019Depression2}.

Recurrent neural networks (RNN)~\cite{8466881} are suitable for learning for time series, better simulate feature changes to improve classification accuracy, and when combined with CNNs can also handle computer vision problems that contain sequential inputs. The LSTM~\cite{2017Exploring}~\cite{2020Automatic2} is also commonly used in facial recognition research, and is suitable for processing and predicting important events with very long intervals and delays in time series, which is more in line with the detection of continuously changing emotions and close to the clinical reality.

Depression alters many behaviors, among which the face presents most of people's nonverbal information. Therefore, facial expressions are highly informative characteristic indicators in the diagnosis of depression, providing more support for clinical studies of depression and offering the possibility of automated detection of depression.


\subsubsection{Performance Comparison}
%\label{sec\_fquality}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Table \ref{tab4} summarizes the results of the experiments on the detection of depression based on facial expressions, including the source and name of the method, the data set used (- means the data used were collected by ourselves), the evaluation criteria of the experimental results, including the classification criteria Accuracy, F1 Score Precision, Recall, the evaluation criteria of depression severity by depression scale mean absolute error (MAE) and root mean square error (RMSE), and Average Error for regression scale scores.

The AVEC competition has greatly advanced research on depression detection based on behavioral performance, and more and more deep algorithms have been applied to depression recognition tasks, all with good results.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table*}
\centering
\caption{Experimental results based on facial}
\label{tab4}
\begin{tabular}{l|l|l|llll|ll|ll}

\hline
\multicolumn{1}{c|}{\multirow{2}{*}{ID}} & \multicolumn{1}{c|}{\multirow{2}{*}{Method}}                         & \multirow{2}{*}{Dataset} & \multicolumn{4}{c|}{Classification}       & \multicolumn{2}{c|}{\shortstack{depression severity \\estimation}} & \multicolumn{2}{c}{Regression}                                \\
                  &                                                                        &                          & Accuracy & F1 Score & Precision & Recall & \multicolumn{1}{c}{RMSE} & \multicolumn{1}{c|}{MAE} & \multicolumn{1}{c}{Scale} & \multicolumn{1}{c}{Average Error} \\
\hline
1                                       & AVEC2013 baseline~\cite{10.1145/2512530.2512533}                                                               & AVEC2013                                     & -        & -          & -         & -      & 13.61                    & 10.88                   & -         & -                  \\
2                                       & AVEC2014 baseline~\cite{10.1145/2661806.2661807}                                                               & AVEC2014                                     & -        & -          & -         & -      & 10.86                    & 8.86                    & -         & -                  \\
3                                       & LPQ+Geo~\cite{2014Eyes}                                                                                        & AVEC2013                                     & -        & -          & -         & -      & 9.72                     & 7.86                    & -         & -                  \\
4                                       & MHH+PLS~\cite{ 2014Automatic}                                                                                  & AVEC2014                                     & -        & -          & -         & -      & 10.5                     & 8.44                    & -         & -                  \\
5                                       & LPQ-TOP+MFA~\cite{2015Automated}                                                                               & AVEC2013                                     & -        & -          & -         & -      & 10.27                    & 8.22                    & -         & -                  \\
6                                       & AVEC2016 baseline~\cite{valstar2016avec}                                                                                     & DAIC-WOZ                                     & -        & 50.00      & 60.00     & 42.80  & 7.13                     & 5.88                    & PHQ       & 7.13               \\
7                                       & Williamson et al.~\cite{2016Detecting}                                                                         & DAIC-WOZ                                     & -        & 53.00      & -         & -      & -                        & -                       & PHQ       & 5.33               \\
8                                       & AVEC2017 baseline~\cite{ringeval2017avec}                                                                      & AVEC2017                                     & -        & -          & -         & -      & 6.97                     & 6.12                    & -         & -                  \\
9                                      & LSTM~\cite{ 2017Exploring}                                                                                     & -                                            & 67.7     & -          & -         & -      & -                        & -                       & -         & -                  \\
10                                      & Two DCNN~\cite{2017Automated}                                                                                  & AVEC2013                                     & -        & -          & -         & -      & 9.82                     & 7.58                    & -         & -                  \\
11                                      & Two DCNN~\cite{2017Automated}                                                                                  & AVEC2014                                     & -        & -          & -         & -      & 9.55                     & 7.47                    & -         & -                  \\
12                                      & SVM+NB+RF~\cite{2018A}                                                                                         & -                                            & 69.10    & -          & -         & -      & -                        & -                       & -         & -                  \\
13                                      & AVEC2019 baseline~\cite{ ringeval2019avec}                                                                     & AVEC201                                      & -        & -          & -         & -      & 8.01                     & -                       & -         & -                  \\
14                                      & C3D~\cite{2019Combining}                                                                                       & AVEC2013                                     & -        & -          & -         & -      & 8.26                     & 6.40                    & -         & -                  \\
15                                      & C3D~\cite{2019Combining}                                                                                       & AVEC2014                                     & -        & -          & -         & -      & 8.31                     & 6.59                    & -         & -                  \\
16                                      & Ray et al.~\cite{ray2019multi}                                                                                 & -                                            & -        & -          & -         & -      & 8.95                     & -                       & -         & -                  \\
17                                      & ResNet-50~\cite{2019Depression2}                                                                               & AVEC2013                                     & -        & -          & -         & -      & 8.25                     & 6.30                    & -         & -                  \\
18                                      & ResNet-50~\cite{2019Depression2}                                                                               & AVEC2014                                     & -        & -          & -         & -      & 8.23                     & 6.15                    & -         & -                  \\
19                                      & ResNet-50+pool~\cite{2019Learning}                                                                             & AVEC2014                                     & -        & -          & -         & -      & 8.43                     & 6.37                    & -         & -                  \\
20                                      & MSN~\cite{ 2020A}                                                                                              & AVEC2013                                     & -        & -          & -         & -      & 7.90                     & 5.98                    & -         & -                  \\
21                                      & MSN~\cite{ 2020A}                                                                                              & AVEC2014                                     & -        & -          & -         & -      & 7.61                     & 5.82                    & -         & -                  \\
22                                      & MR-DepressNet~\cite{2020Visually}                                                                              & AVEC2013                                     & -        & -          & -         & -      & 8.28                     & 6.20                    & -         & -                  \\
23                                      & MR-DepressNet~\cite{2020Visually}                                                                              & AVEC2014                                     & -        & -          & -         & -      & 8.39                     & 6.21                    & -         & -                  \\
24                                      & Two-Stream model~\cite{2020Encoding}                                                                           & AVEC2013                                     & -        & -          & -         & -      & 7.97                     & 5.96                    & -         & -                  \\
25                                      & Two-Stream model~\cite{2020Encoding}                                                                           & AVEC2014                                     & -        & -          & -         & -      & 7.94                     & 6.20                    & -         & -                  \\
26                                      & CNN~\cite{2020Automatic}                                                                                       & -                                            & 66.45    & -          & -         & -      & -                        & -                       & -         & -                  \\
27                                      & SS-LSTM-MIL~\cite{2020Automatic2}                                                                              & DAC-WOZ                                      & -        & 78.3       & 81.80     & 75.00  & -                        & -                       & -         & -                  \\
28                                      & \begin{tabular}[c]{@{}l@{}}RNN-C3D Tight-Face \& Loose-Face\\ \\weighted merge~\cite{8466881}\end{tabular} & AVEC2013                                     & -        & -          & -         & -      & 9.28                     & 7.37                    & -         & -                  \\
29                                      & \begin{tabular}[c]{@{}l@{}}RNN-C3D Tight-Face \& Loose-Face\\ \\weighted merge~\cite{8466881}\end{tabular} & AVEC2014                                     & -        & -          & -         & -      & 9.20                     & 7.22                    & -         & -                 \\
\hline

\end{tabular}
\end{table*}



\ifx\allfiles\undefined
\input{tnnls\_suffix}
\fi
